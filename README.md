# Proyecto-An-lisis-de-Datos-con-Python
Análisis de datos con Python utilizando bibliotecas como Polars y Numpy. Incluye carga, limpieza, visualización, modelado y evaluación de datos reales de salud, vivienda, consumo de agua y entretenimiento. Cada ejercicio está estructurado en carpetas independientes con notebooks y datasets.


Cada carpeta contiene:
- `notebook.ipynb`: Cuaderno con el desarrollo del análisis.
- `dataset/`: Carpeta con los datos utilizados.

---

## 🧠 Ejercicios

### 🔹 Ejercicio 1: Predicción de Riesgo de Diabetes
- **Objetivo:** Predecir si una paciente femenina tiene diabetes usando registros médicos.
- **Dataset:** Diabetes Dataset.
- **Modelos propuestos:** Regresión logística, KNN, Random Forest.

### 🔹 Ejercicio 2: Análisis de Condiciones de Vivienda (ENIGH)
- **Objetivo:** Analizar condiciones de vivienda en México y predecir carencias habitacionales.
- **Dataset:** Encuesta ENIGH 2022.
- **Modelos propuestos:** Árbol de decisión, Random Forest, Regresión logística.

### 🔹 Ejercicio 3: Predicción de Consumo Excesivo de Agua
- **Objetivo:** Determinar si una manzana de la CDMX tendrá consumo excesivo de agua en el próximo periodo.
- **Dataset:** Datos Abiertos de la CDMX.
- **Modelos propuestos:** Árbol de decisión, Random Forest, Regresión logística.

### 🔹 Ejercicio 4: Sistema de Recomendación de Películas
- **Objetivo:** Crear un recomendador basado en calificaciones de usuarios.
- **Dataset:** MovieLens.
- **Modelos propuestos:** KNN.
- **Extra:** Simulación de sistema con StreamLit (opcional).

---

## 🔧 Herramientas y Librerías

- Python 3.x
- [Polars](https://www.pola.rs/)
- Numpy
- Matplotlib / Seaborn (para visualización)
- Scikit-learn (modelos ML)
- StreamLit (opcional, para UI del recomendador)

---

## 📈 Flujo de Trabajo por Ejercicio

1. **Carga y Exploración de Datos**
2. **Limpieza Básica**
3. **Análisis Exploratorio y Visualización**
4. **Preprocesamiento Técnico**
5. **Entrenamiento del Modelo**
6. **Evaluación del Modelo**
7. **Visualización de Resultados**

---

## 📝 Créditos

Este proyecto fue desarrollado como parte de una práctica académica para aplicar conocimientos de análisis de datos y aprendizaje automático.


